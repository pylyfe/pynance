{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Investment Decisions Using Machine Learning\n",
    "\n",
    "In this project we will be using Machine Learning to process financial data, and use them to make investment decisions. We will mainly focus on whether or not we should buy, sell or hold a particular stock given the information that we have. \n",
    "\n",
    "Here we will also learn how to pull out data, process them and then perform some of the most important machine learning algorithms to analyze these data. The data that we will be using are the tickers that are available in the S&P 500. \n",
    "\n",
    "Since this is going to be quite a long project, we will not be making all the necessary imports at once, and instead we will be importing libraries along the way as we require them. \n",
    "\n",
    "First imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs # Beautiful Soup\n",
    "import pickle \n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first be pulling all ticker symbols of companies available in S&P 500 using BeautifulSoup4, which turns source code from a website into a BeautifulSoup object that can be treated like a typical Python object. \n",
    "\n",
    "We will be extracting these ticker symbols from Wikipedia using the request.get() method. Finally, we will specify the exact table that we need to get to the actual ticker symbols that we want to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request information from Wikipedia by using the web link\n",
    "resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "\n",
    "# Extract the text using lxml (toolkit to process html and xml using Python)\n",
    "soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "# Find and extract the particular table that we want\n",
    "table = soup.find('table', {'class': 'wikitable sortable'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For line 8 of the code above, it simply means that we are extracting a table that has a class name of \"wikitable sortable\", as can be shown below (taken from the wikipedia page source code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"wikipedia.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
